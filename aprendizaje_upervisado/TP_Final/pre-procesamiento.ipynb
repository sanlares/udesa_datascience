{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Con esto lo bajamos de este repositorio centralizado\n",
    "ds = load_dataset(\"ag_news\")\n",
    "\n",
    "vect = CountVectorizer()\n",
    "# Si quisieramos que considere en el diccionario secuencia de un caracter (como la palabra \"y\", hay que modificar el parámetro token_pattern al instanciar CountVectorizer\n",
    "# vect = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')\n",
    "vect.fit(ds[\"train\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz=vect.transform(ds[\"train\"][\"text\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a pandas\n",
    "\n",
    "id2label = ds[\"train\"].features[\"label\"].names\n",
    "\n",
    "df_train = ds[\"train\"].to_pandas()\n",
    "\n",
    "df_test = ds[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos una proporción de la muestra de entrenamiento para que el entrenamiento sea más eficiente computacionalmente\n",
    "muestra_fraccion = 0.01\n",
    "df_train_muestra= df_train.sample(frac=muestra_fraccion, random_state=42)\n",
    "\n",
    "# Hacemos el pre procesamiento con count_vectorizer()\n",
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(df_train_muestra['text'])\n",
    "y_train = df_train_muestra['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener el vocabulario generado por el CountVectorizer\n",
    "vocabulario = vect.get_feature_names_out()\n",
    "\n",
    "# Mostrar las primeras 50 palabras del vocabulario\n",
    "print(vocabulario[:50])\n",
    "\n",
    "# Si deseas conocer el tamaño total del vocabulario\n",
    "print(\"\\nTamaño total del vocabulario:\", len(vocabulario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df_train_muestra['text'].sample(10):\n",
    "    print(text)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(token_pattern=r'\\b[a-zA-Z]+\\b')  # Esto excluye los números y captura solo palabras alfabéticas\n",
    "X_train = vect.fit_transform(df_train_muestra['text'])\n",
    "# Obtener y mostrar el vocabulario\n",
    "vocabulario_alfabetico = vect.get_feature_names_out()\n",
    "\n",
    "print(vocabulario_alfabetico[:50])  # Mostramos las primeras 50 palabras del vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
